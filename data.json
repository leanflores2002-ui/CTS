{
  "meta": {
    "heroImage": "https://raw.githubusercontent.com/leanflores2002-ui/etica-ai-futuro/main/src/assets/transparency-ai.jpg"
  },
  "topics": [
    {
      "emoji": "⚖️",
      "title": "Sesgo Algorítmico",
      "description": "Cómo los modelos pueden amplificar prejuicios presentes en los datos y qué medidas aplicar.",
      "image": "https://raw.githubusercontent.com/leanflores2002-ui/etica-ai-futuro/main/src/assets/bias-algorithms.jpg"
    },
    {
      "emoji": "🔒",
      "title": "Privacidad",
      "description": "Protección de datos personales y principios para diseñar sistemas respetuosos con la privacidad.",
      "image": "https://raw.githubusercontent.com/leanflores2002-ui/etica-ai-futuro/main/src/assets/privacy-data.jpg"
    },
    {
      "emoji": "🔍",
      "title": "Transparencia",
      "description": "Entender y comunicar cómo funcionan las decisiones automáticas.",
      "image": "https://raw.githubusercontent.com/leanflores2002-ui/etica-ai-futuro/main/src/assets/transparency-ai.jpg"
    },
    {
      "emoji": "👥",
      "title": "Responsabilidad",
      "description": "Quién responde cuando la IA causa daño y cómo establecer auditorías.",
      "image": "https://raw.githubusercontent.com/leanflores2002-ui/etica-ai-futuro/main/src/assets/accountability.jpg"
    },
    {
      "emoji": "🌍",
      "title": "Impacto Social",
      "description": "Efectos en empleo, desigualdad y políticas públicas.",
      "image": "https://raw.githubusercontent.com/leanflores2002-ui/etica-ai-futuro/main/src/assets/social-impact.jpg"
    }
  ],
  "cases": [
    {
      "title": "Amazon Recruiting — sesgo en selección",
      "description": "Un sistema entrenado con CV históricos reprodujo sesgos de género. Necesidad: datasets representativos y auditorías continuas.",
      "image": "https://raw.githubusercontent.com/leanflores2002-ui/etica-ai-futuro/main/src/assets/amazon-face-recognition.jpg"
    },
    {
      "title": "Reconocimiento facial — precisión desigual",
      "description": "Errores más altos en mujeres y personas de piel oscura; riesgo en aplicaciones policiales y de seguridad.",
      "image": "https://raw.githubusercontent.com/leanflores2002-ui/etica-ai-futuro/main/src/assets/facial-recognition.jpg"
    }
  ],
  "resources": [
    {
      "name": "Partnership on AI",
      "url": "https://www.partnershiponai.org",
      "description": "Buenas prácticas y recomendaciones globales.",
      "icon": "🏛️"
    },
    {
      "name": "Google — Responsible AI",
      "url": "https://ai.google/responsibilities",
      "description": "Guías y herramientas para diseño responsable.",
      "icon": "📚"
    },
    {
      "name": "Oxford Insights",
      "url": "https://www.oxfordinsights.com",
      "description": "Investigación sobre gobernanza y políticas públicas.",
      "icon": "🔎"
    },
    {
      "name": "ITU — AI for Good",
      "url": "https://www.itu.int/en/ITU-D/AI/Pages/default.aspx",
      "description": "Iniciativas y estándares internacionales.",
      "icon": "🌐"
    }
  ]
}